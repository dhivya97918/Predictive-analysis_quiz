# -*- coding: utf-8 -*-
"""Predictive Analysis_quiz.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MfmChs8moSBIXw5EPITcl04YhMPkkNd_
"""

import pandas as pd

# Load the CSV file into a DataFrame
data = pd.read_csv("/content/sample_data/DSAI-LVA-DATASET for Quiz.csv")
print(len(data))
train_data = data.sample(frac=0.8)
test_data = data.drop(train_data.index)

# Save the train and test sets to separate CSV files
train_data.to_csv("train_data.csv", index=False)
test_data.to_csv("test_data.csv", index=False)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import random
# Load the dataset
data = pd.read_csv('/content/sample_data/DSAI-LVA-DATASET for Quiz.csv')

data.head()

data.info()

parent_education_mapping = {
    'HighSchool': np.random.choice(['HighSchool', 'School', 'Not Educated'], size=len(data)),
    'College': np.random.choice(['Masters', 'Bachelors'], size=len(data))
}
data['ParentEducation'] = data['ParentEducation'].map(lambda x: np.random.choice(parent_education_mapping[x]))

def categorize_score(pass_status, score):
    if pass_status == 'Yes' and score >= 90:
        return 1
    elif pass_status == 'Yes' and score < 90:
        return 2
    elif pass_status == 'No':
        return 3
    else:
        return np.nan

data['Pass'] = data.apply(lambda row: categorize_score(row['Pass'], row['PreviousTestScore']), axis=1)

print(data)

label_encoder = LabelEncoder()
data['ParentEducation'] = label_encoder.fit_transform(data['ParentEducation'])

print(data)

total_rows = len(data)
train_rows = int(0.8 * total_rows)
test_rows = total_rows - train_rows

# Shuffle the DataFrame to ensure randomness
data_shuffled = data.sample(frac=1, random_state=42)

# Split the DataFrame into training and testing subsets
train_data = data_shuffled.iloc[:train_rows]
test_data = data_shuffled.iloc[train_rows:]

# Write training and testing data to CSV files
train_data.to_csv('/content/sample_data/train_data.csv', index=False)
test_data.to_csv('/content/sample_data/test_data.csv', index=False)

import xgboost as xgb

train_data = pd.read_csv('/content/sample_data/train_data.csv')
test_data = pd.read_csv('/content/sample_data/test_data.csv')

train_data['Pass'] = label_encoder.fit_transform(train_data['Pass'])
test_data['Pass'] = label_encoder.fit_transform(test_data['Pass'])
# Define X and y for training and testing data
X_train = train_data.drop('Pass', axis=1)
y_train = train_data['Pass']
X_test = test_data.drop('Pass', axis=1)
y_test = test_data['Pass']

# Model Engineering
models = {
    'Random Forest': RandomForestClassifier(),
    'Logistic Regression': LogisticRegression(),
    'Decision Tree': DecisionTreeClassifier(),
    'XGBoost': xgb.XGBClassifier()  # XGBoost added
}

results = {}

for name, model in models.items():
    # Train the model
    model.fit(X_train, y_train)

    # Predictions
    y_pred = model.predict(X_test)

    # Model evaluation
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy

    print(f"Model: {name}")
    print(f"Accuracy: {accuracy:.2f}")
    print(classification_report(y_test, y_pred))
    print(confusion_matrix(y_test, y_pred))
    print("="*50)

# Model comparison
print("Model Comparison:")
for name, accuracy in results.items():
    print(f"{name}: {accuracy:.2f}")

# Visualization
# Confusion Matrix
plt.figure(figsize=(12, 8))
for i, (name, model) in enumerate(models.items()):
    plt.subplot(2, 3, i+1)
    sns.heatmap(confusion_matrix(y_test, model.predict(X_test)), annot=True, fmt="d", cmap="Blues")
    plt.title(name)
plt.tight_layout()
plt.show()

# Write model comparison and outcome to a file
with open('model_comparison.txt', 'w') as f:
    f.write("Model Comparison:\n")
    for name, accuracy in results.items():
        f.write(f"{name}: {accuracy:.2f}\n")